{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import polars as pl\n",
    "from ebrec.utils._constants import *\n",
    "from ebrec.utils._python import compute_npratio, create_lookup_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install matplotlib seaborn\n",
    "%pip install pyarrow\n",
    "%pip install pandas\n",
    "%pip install xlsx2csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.ticker as mticker\n",
    "from matplotlib.ticker import MaxNLocator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Help functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EB_COLOR = \"#bd1118\"\n",
    "\n",
    "\n",
    "def save_figure(fig, save_path: str = None) -> None:\n",
    "    if save_path is not None:\n",
    "        path = Path(save_path)\n",
    "        path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        fig.savefig(path, dpi=300)\n",
    "\n",
    "\n",
    "def plot_histogram(\n",
    "    df: pl.DataFrame,\n",
    "    column_name: str = None,\n",
    "    stat: str = \"density\",\n",
    "    save_path: str = None,\n",
    "    x_max: int = None,\n",
    "    y_max: int = None,\n",
    "    binwidth: int = None,\n",
    "    num_xticks: int = None,\n",
    "    num_yticks: int = None,\n",
    "    fontsize: int = 12,\n",
    "    bins: int = \"auto\",\n",
    ") -> None:\n",
    "    # =>\n",
    "    fig, ax = plt.subplots(figsize=(18, 14))\n",
    "    sns.set_theme(style=\"whitegrid\", font_scale=fontsize / 12)\n",
    "    sns.histplot(\n",
    "        data=df,\n",
    "        x=column_name,\n",
    "        color=EB_COLOR,\n",
    "        binwidth=binwidth,\n",
    "        alpha=0.5,\n",
    "        stat=stat,\n",
    "        bins=bins,\n",
    "    )\n",
    "    if x_max is not None:\n",
    "        ax.set_xlim([0, x_max])\n",
    "    if y_max is not None:\n",
    "        ax.set_ylim([0, y_max])\n",
    "    ax.yaxis.set_major_formatter(mticker.ScalarFormatter(useMathText=True))\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True, nbins=num_xticks))\n",
    "    if num_yticks is not None:\n",
    "        ax.yaxis.set_major_locator(MaxNLocator(nbins=num_yticks, prune=\"lower\"))\n",
    "\n",
    "    plt.grid(axis=\"x\")\n",
    "    plt.title(\"\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(stat.capitalize())\n",
    "    plt.ticklabel_format(style=\"sci\", axis=\"y\", scilimits=(0, 0))\n",
    "    plt.tight_layout()\n",
    "    save_figure(fig, save_path=save_path)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def create_bar_plot(\n",
    "    df: pd.DataFrame,\n",
    "    x_col: str,\n",
    "    y_col: str,\n",
    "    xlabel: str = \"\",\n",
    "    ylabel: str = \"\",\n",
    "    title: str = None,\n",
    "    rotation: int = 0,\n",
    "    fontsize: int = 12,\n",
    "    colors: list[str] = None,\n",
    "    y_as_percentage: bool = False,\n",
    "    y_max: float = None,\n",
    "    save_path: str = None,\n",
    "):\n",
    "    # Set style\n",
    "    sns.set_theme(style=\"whitegrid\", font_scale=fontsize / 12)\n",
    "    # Create bar plot\n",
    "    fig, ax = plt.subplots(figsize=(18, 14))\n",
    "    ax = sns.barplot(\n",
    "        data=df,\n",
    "        x=x_col,\n",
    "        y=y_col,\n",
    "        alpha=0.80,\n",
    "        palette=colors,\n",
    "        legend=False,\n",
    "        hue=x_col,\n",
    "    )\n",
    "    if y_as_percentage:\n",
    "        # Format y-axis labels as percentage\n",
    "        ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{x:.0%}\"))\n",
    "    if y_max is not None:\n",
    "        ax.set_ylim([0, y_max])\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "    # Set labels and title\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xticks(rotation=rotation)\n",
    "\n",
    "    # Remove top and right borders\n",
    "    # sns.despine()\n",
    "    plt.tight_layout()\n",
    "    save_figure(fig, save_path=save_path)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def create_plot(\n",
    "    x,\n",
    "    xlabel: str = \"\",\n",
    "    ylabel: str = \"\",\n",
    "    title: str = None,\n",
    "    rotation: int = 0,\n",
    "    marker: str = \"\",\n",
    "    linestyle: str = \"-\",\n",
    "    fontsize: int = 12,\n",
    "    markersize: float = 2.0,\n",
    "    linewidth: float = 2.0,\n",
    "    color: str = None,\n",
    "    y_as_percentage: bool = False,\n",
    "    y_max: float = None,\n",
    "    x_max: float = None,\n",
    "    num_xticks: int = None,\n",
    "    num_yticks: int = None,\n",
    "    save_path: str = None,\n",
    "):\n",
    "    fig, ax = plt.subplots(figsize=(18, 14))\n",
    "    plt.plot(\n",
    "        x,\n",
    "        linewidth=linewidth,\n",
    "        color=color,\n",
    "        marker=marker,\n",
    "        markersize=markersize,\n",
    "        linestyle=linestyle,\n",
    "    )\n",
    "    if y_as_percentage:\n",
    "        ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{x:.0%}\"))\n",
    "    else:\n",
    "        ax.yaxis.set_major_formatter(mticker.ScalarFormatter(useMathText=True))\n",
    "    if y_max is not None:\n",
    "        ax.set_ylim([0, y_max])\n",
    "    if x_max is not None:\n",
    "        ax.set_xlim([0, x_max])\n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=fontsize)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True, nbins=num_xticks))\n",
    "    if num_yticks is not None:\n",
    "        ax.yaxis.set_major_locator(MaxNLocator(nbins=num_yticks, prune=\"lower\"))\n",
    "\n",
    "    ax.set_xlabel(xlabel, fontsize=fontsize)\n",
    "    ax.set_ylabel(ylabel, fontsize=fontsize)\n",
    "    ax.tick_params(axis=\"x\", labelsize=fontsize)\n",
    "    ax.tick_params(axis=\"y\", labelsize=fontsize)\n",
    "    plt.xticks(rotation=rotation)\n",
    "    plt.tight_layout()\n",
    "    save_figure(fig, save_path=save_path)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def add_word_count_column(\n",
    "    df: pl.DataFrame, column: str, column_alias: str\n",
    ") -> pl.DataFrame:\n",
    "    return df.with_columns(\n",
    "        pl.when(pl.col(column) != \"\")\n",
    "        .then(pl.col(column).str.split(by=\" \").list.len())\n",
    "        .otherwise(0)\n",
    "        .alias(column_alias)\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\"~/Git Repositories/ebnerd-benchmark/data\")\n",
    "TRAIN_VAL_SPLIT = f\"ebnerd_large\"  # [ebnerd_demo, ebnerd_small, ebnerd_large]\n",
    "TEST_SPLIT = f\"ebnerd_testset\"  # \"ebnerd_testset\", \"ebnerd_testset_gt\"\n",
    "\n",
    "df_behaviors_train = df_behaviors = pl.scan_parquet(\n",
    "    PATH.joinpath(TRAIN_VAL_SPLIT, \"train\", \"behaviors.parquet\")\n",
    ")\n",
    "df_history_train = df_behaviors = pl.scan_parquet(\n",
    "    PATH.joinpath(TRAIN_VAL_SPLIT, \"train\", \"history.parquet\")\n",
    ")\n",
    "df_behaviors_val = df_behaviors = pl.scan_parquet(\n",
    "    PATH.joinpath(TRAIN_VAL_SPLIT, \"validation\", \"behaviors.parquet\")\n",
    ")\n",
    "df_history_val = df_behaviors = pl.scan_parquet(\n",
    "    PATH.joinpath(TRAIN_VAL_SPLIT, \"validation\", \"history.parquet\")\n",
    ")\n",
    "df_behaviors_test = df_behaviors = (\n",
    "    pl.scan_parquet(PATH.joinpath(TEST_SPLIT, \"test\", \"behaviors.parquet\"))\n",
    "    .filter(~pl.col(DEFAULT_IS_BEYOND_ACCURACY_COL))\n",
    "    .drop(DEFAULT_IS_BEYOND_ACCURACY_COL)\n",
    ")\n",
    "df_history_test = df_behaviors = pl.scan_parquet(\n",
    "    PATH.joinpath(TEST_SPLIT, \"test\", \"history.parquet\")\n",
    ")\n",
    "df_behaviors_test_ba = df_behaviors = pl.scan_parquet(\n",
    "    PATH.joinpath(TEST_SPLIT, \"test\", \"behaviors.parquet\")\n",
    ").filter(pl.col(DEFAULT_IS_BEYOND_ACCURACY_COL))\n",
    "df_articles = pl.scan_parquet(PATH.joinpath(\"articles.parquet\")).collect()\n",
    "\n",
    "PLOT_PATH = Path(\"plot\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some help names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_INVIEW_ARTICLES = \"inview_len\"\n",
    "N_WORDS_TITLE = \"title_len\"\n",
    "N_WORDS_SUBTITLE = \"subtitle_len\"\n",
    "N_WORDS_BODY = \"body_len\"\n",
    "CATEGORY_DIST_NAME = \"category_distribution\"\n",
    "FONTSIZE = 90"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEFAULT_CLICKED_ARTICLES_COL not in df_behaviors_test.columns:\n",
    "    df_behaviors_test = df_behaviors_test.with_columns(\n",
    "        pl.Series(DEFAULT_CLICKED_ARTICLES_COL, [[0]], dtype=pl.List(pl.Int32))\n",
    "    )\n",
    "\n",
    "df_behaviors = pl.concat(\n",
    "    [df_behaviors_train, df_behaviors_val, df_behaviors_test]\n",
    ").with_columns(pl.col(DEFAULT_INVIEW_ARTICLES_COL).list.len().alias(N_INVIEW_ARTICLES))\n",
    "\n",
    "df_history = pl.concat([df_history_train, df_history_val, df_history_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_HIST_COL = \"impression_time_fixed\"\n",
    "df_history_unique_hist_interactions = (\n",
    "    df_history.select(DEFAULT_USER_COL, pl.col(TIME_HIST_COL))\n",
    "    .explode(TIME_HIST_COL)\n",
    "    .group_by(DEFAULT_USER_COL)\n",
    "    .agg(pl.col(TIME_HIST_COL).unique())\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles = (\n",
    "    df_articles.pipe(add_word_count_column, column=\"title\", column_alias=N_WORDS_TITLE)\n",
    "    .pipe(add_word_count_column, column=\"subtitle\", column_alias=N_WORDS_SUBTITLE)\n",
    "    .pipe(add_word_count_column, column=\"body\", column_alias=N_WORDS_BODY)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset overview:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behaviors Train/Val:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_behaviors_train.columns)\n",
    "df_behaviors_train.head(2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_history.head(2).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Articles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_articles.columns)\n",
    "df_articles.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More descriptive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pos = (\n",
    "    df_behaviors.select(pl.col(DEFAULT_CLICKED_ARTICLES_COL).list.len()).sum().collect()\n",
    ")[DEFAULT_CLICKED_ARTICLES_COL][0]\n",
    "n_neg = (\n",
    "    df_behaviors.select(\n",
    "        pl.col(DEFAULT_INVIEW_ARTICLES_COL).list.len()\n",
    "        - pl.col(DEFAULT_CLICKED_ARTICLES_COL).list.len()\n",
    "    )\n",
    "    .sum()\n",
    "    .collect()\n",
    ")[DEFAULT_INVIEW_ARTICLES_COL][0]\n",
    "\n",
    "n_samples_in_history = df_history_unique_hist_interactions.select(\n",
    "    pl.col(TIME_HIST_COL).list.len()\n",
    ").sum()[TIME_HIST_COL][0]\n",
    "\n",
    "n_impressions = df_behaviors.select(DEFAULT_USER_COL).collect().shape[0]\n",
    "\n",
    "n_users = df_behaviors.select(DEFAULT_USER_COL).unique().collect().shape[0]\n",
    "n_sso_users = (\n",
    "    df_behaviors.select(DEFAULT_USER_COL, DEFAULT_IS_SSO_USER_COL)\n",
    "    .unique()\n",
    "    .select(pl.col(DEFAULT_IS_SSO_USER_COL))\n",
    "    .sum()\n",
    "    .collect()[DEFAULT_IS_SSO_USER_COL][0]\n",
    ")\n",
    "n_subscriber_users = (\n",
    "    df_behaviors.select(DEFAULT_USER_COL, DEFAULT_IS_SUBSCRIBER_COL)\n",
    "    .unique()\n",
    "    .sum()\n",
    "    .collect()[DEFAULT_IS_SUBSCRIBER_COL][0]\n",
    ")\n",
    "n_articles = df_articles.select(DEFAULT_ARTICLE_ID_COL).unique().shape[0]\n",
    "n_categories = df_articles.select(DEFAULT_CATEGORY_COL).unique().shape[0]\n",
    "n_subcategories = (\n",
    "    df_articles.select(pl.col(DEFAULT_SUBCATEGORY_COL).explode()).unique().shape[0]\n",
    ")\n",
    "\n",
    "descriptive_dict = {\n",
    "    f\"# News\": n_articles,\n",
    "    f\"# Users (unique)\": n_users,\n",
    "    f\"# News categories\": n_categories,\n",
    "    f\"# Impressions\": n_impressions,\n",
    "    f\"# History Interactions\": n_samples_in_history,\n",
    "    f\"# Total dataset interactions (Impressions + History)\": n_impressions\n",
    "    + n_samples_in_history,\n",
    "    f\"# News subcategories\": n_subcategories,\n",
    "    f\"# Positive\": n_pos,\n",
    "    f\"# Negative\": n_neg,\n",
    "    f\"NP-ratio\": round(compute_npratio(n_pos=n_pos, n_neg=n_neg), 2),\n",
    "    f\"Avg. impression per user\": round(n_impressions / n_users, 2),\n",
    "    f\"Avg. title len. (words)\": round(\n",
    "        df_articles.select(pl.col(N_WORDS_TITLE)).mean()[N_WORDS_TITLE][0], 2\n",
    "    ),\n",
    "    f\"Std. title len. (words)\": round(\n",
    "        df_articles.select(pl.col(N_WORDS_TITLE)).std()[N_WORDS_TITLE][0], 2\n",
    "    ),\n",
    "    f\"Avg. abstract len. (words)\": round(\n",
    "        df_articles.select(pl.col(N_WORDS_SUBTITLE)).mean()[N_WORDS_SUBTITLE][0],\n",
    "        2,\n",
    "    ),\n",
    "    f\"Std. abstract len. (words)\": round(\n",
    "        df_articles.select(pl.col(N_WORDS_SUBTITLE)).std()[N_WORDS_SUBTITLE][0],\n",
    "        2,\n",
    "    ),\n",
    "    f\"Avg. body len. (words)\": round(\n",
    "        df_articles.select(pl.col(N_WORDS_BODY)).mean()[N_WORDS_BODY][0],\n",
    "        2,\n",
    "    ),\n",
    "    f\"Std. body len. (words)\": round(\n",
    "        df_articles.select(pl.col(N_WORDS_BODY)).std()[N_WORDS_BODY][0],\n",
    "        2,\n",
    "    ),\n",
    "    f\"# SSO users\": n_sso_users,\n",
    "    f\"# Subscriber users\": n_subscriber_users,\n",
    "}\n",
    "_ = [print(f\"{key}: {value}\") for key, value in descriptive_dict.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_overlap(df1, df2):\n",
    "    df_concat = pl.concat([df1, df2]).unique().shape[0]\n",
    "    return df1.shape[0] / df_concat\n",
    "\n",
    "\n",
    "users_train = df_behaviors_train.select(pl.col(DEFAULT_USER_COL).unique()).collect()\n",
    "users_valid = df_behaviors_val.select(pl.col(DEFAULT_USER_COL).unique()).collect()\n",
    "users_test = df_behaviors_test.select(pl.col(DEFAULT_USER_COL).unique()).collect()\n",
    "train_val, train_test, val_test, train_ValTest, val_TrainTest, test_TrainVal = (\n",
    "    compute_overlap(users_train, users_valid),\n",
    "    compute_overlap(users_train, users_test),\n",
    "    compute_overlap(users_valid, users_test),\n",
    "    compute_overlap(users_train, pl.concat([users_valid, users_test]).unique()),\n",
    "    compute_overlap(users_valid, pl.concat([users_train, users_test]).unique()),\n",
    "    compute_overlap(users_test, pl.concat([users_train, users_valid]).unique()),\n",
    ")\n",
    "print(f\"Train-Val overlap: {round(train_val*100,2)}%\")\n",
    "print(f\"Train-Test overlap: {round(train_test*100, 2)}%\")\n",
    "print(f\"Val-Test overlap: {round(val_test*100, 2)}%\")\n",
    "print(f\"Train-(Val+Test) overlap: {round(train_ValTest*100, 2)}%\")\n",
    "print(f\"Val-(Train+Test) overlap: {round(val_TrainTest*100, 2)}%\")\n",
    "print(f\"Test-(Train+Val) overlap: {round(test_TrainVal*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_total = (\n",
    "    df_behaviors.select(DEFAULT_USER_COL, DEFAULT_GENDER_COL)\n",
    "    .drop_nulls()\n",
    "    .group_by(DEFAULT_USER_COL)\n",
    "    .agg(pl.col(DEFAULT_GENDER_COL).first())\n",
    "    .collect()\n",
    ")\n",
    "m_total = gender_total.filter(pl.col(DEFAULT_GENDER_COL) == 0).shape[0]\n",
    "w_total = gender_total.filter(pl.col(DEFAULT_GENDER_COL) == 1).shape[0]\n",
    "m_w_total = m_total + w_total\n",
    "print(\n",
    "    f\"Users with 'gender' in total dataset: {m_w_total}, where {m_total} are men ({round(m_total/m_w_total*100, 2)}%) and {w_total} are women ({round(w_total/m_w_total*100, 2)}%)\"\n",
    ")\n",
    "gender_ba = (\n",
    "    df_behaviors_test_ba.select(\n",
    "        DEFAULT_USER_COL, DEFAULT_GENDER_COL, DEFAULT_IS_BEYOND_ACCURACY_COL\n",
    "    )\n",
    "    .drop_nulls()\n",
    "    .group_by(DEFAULT_USER_COL)\n",
    "    .agg(pl.col(DEFAULT_GENDER_COL).first())\n",
    "    .collect()\n",
    ")\n",
    "m_ba = gender_ba.filter(pl.col(DEFAULT_GENDER_COL) == 0).shape[0]\n",
    "w_ba = gender_ba.filter(pl.col(DEFAULT_GENDER_COL) == 1).shape[0]\n",
    "m_w_ba = m_ba + w_ba\n",
    "print(\n",
    "    f\"Users with 'gender' in beyond-accuracy dataset: {m_w_ba}, where {m_ba} are men ({round(m_ba/m_w_ba*100, 2)}%) and {w_ba} are women ({round(w_ba/m_w_ba*100, 2)}%)\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# Visualizations:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textual features in Articles:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "print(df_articles[N_WORDS_TITLE].describe())\n",
    "plot_histogram(\n",
    "    df_articles.filter(pl.col(N_WORDS_TITLE) <= 18).select(N_WORDS_TITLE),\n",
    "    num_xticks=4,\n",
    "    num_yticks=3,\n",
    "    fontsize=FONTSIZE,\n",
    "    binwidth=1,\n",
    "    column_name=N_WORDS_TITLE,\n",
    "    save_path=PLOT_PATH.joinpath(N_WORDS_TITLE + \".png\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtitle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_articles[N_WORDS_SUBTITLE].describe())\n",
    "plot_histogram(\n",
    "    df_articles.filter(pl.col(N_WORDS_SUBTITLE) <= 50).select(N_WORDS_SUBTITLE),\n",
    "    num_xticks=4,\n",
    "    num_yticks=3,\n",
    "    fontsize=FONTSIZE,\n",
    "    binwidth=1,\n",
    "    column_name=N_WORDS_SUBTITLE,\n",
    "    save_path=PLOT_PATH.joinpath(N_WORDS_SUBTITLE + \".png\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_articles[N_WORDS_BODY].describe())\n",
    "plot_histogram(\n",
    "    df_articles.filter(pl.col(N_WORDS_BODY) <= 1200).select(N_WORDS_BODY),\n",
    "    num_xticks=4,\n",
    "    num_yticks=3,\n",
    "    fontsize=FONTSIZE,\n",
    "    bins=70,\n",
    "    binwidth=None,\n",
    "    column_name=N_WORDS_BODY,\n",
    "    save_path=PLOT_PATH.joinpath(N_WORDS_BODY + \".png\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of in-view articles per impression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_behaviors.select(N_INVIEW_ARTICLES).describe())\n",
    "# =>\n",
    "plot_histogram(\n",
    "    df_behaviors.select(N_INVIEW_ARTICLES).collect(),\n",
    "    x_max=30,\n",
    "    num_xticks=4,\n",
    "    num_yticks=3,\n",
    "    fontsize=90,\n",
    "    binwidth=1,\n",
    "    column_name=N_INVIEW_ARTICLES,\n",
    "    save_path=PLOT_PATH.joinpath(N_INVIEW_ARTICLES + f\".png\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Front vs. Article page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frontpage = (\n",
    "    pl.concat([df_behaviors_train, df_behaviors_val])\n",
    "    .select(DEFAULT_ARTICLE_ID_COL, DEFAULT_READ_TIME_COL)\n",
    "    .filter(pl.col(DEFAULT_ARTICLE_ID_COL).is_null())\n",
    "    .collect()\n",
    ")\n",
    "df_articlepage = (\n",
    "    pl.concat([df_behaviors_train, df_behaviors_val])\n",
    "    .select(DEFAULT_ARTICLE_ID_COL, DEFAULT_READ_TIME_COL)\n",
    "    .filter(pl.col(DEFAULT_ARTICLE_ID_COL).is_not_null())\n",
    "    .collect()\n",
    ")\n",
    "total_ = df_frontpage.shape[0] + df_articlepage.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inviews - front- vs. article page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_page_frac = round(df_articlepage.shape[0] / total_, 2)\n",
    "frontpage_frac = round(1 - article_page_frac, 2)\n",
    "#\n",
    "sizes = [frontpage_frac, article_page_frac]\n",
    "labels = f\"Frontpage ({frontpage_frac})\", f\"ArticlePage ({article_page_frac})\"\n",
    "fig, ax = plt.subplots()\n",
    "front_article_page = ax.pie(sizes, labels=labels, colors=[\"blue\", \"orange\"])\n",
    "plt.tight_layout()\n",
    "save_figure(fig, save_path=PLOT_PATH.joinpath(\"front_article_page.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Readtime - front- vs. article page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SHOW = 120\n",
    "plot_histogram(\n",
    "    df_frontpage.filter(pl.col(DEFAULT_READ_TIME_COL) < N_SHOW).select(\n",
    "        DEFAULT_READ_TIME_COL\n",
    "    ),\n",
    "    column_name=DEFAULT_READ_TIME_COL,\n",
    "    x_max=N_SHOW,\n",
    "    bins=60,\n",
    "    num_xticks=6,\n",
    "    fontsize=90,\n",
    "    save_path=PLOT_PATH.joinpath(\"front_read_time.png\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SHOW = 240\n",
    "plot_histogram(\n",
    "    df_articlepage.filter(pl.col(DEFAULT_READ_TIME_COL) < N_SHOW).select(\n",
    "        DEFAULT_READ_TIME_COL\n",
    "    ),\n",
    "    column_name=DEFAULT_READ_TIME_COL,\n",
    "    x_max=N_SHOW,\n",
    "    bins=60,\n",
    "    num_xticks=6,\n",
    "    fontsize=90,\n",
    "    save_path=PLOT_PATH.joinpath(\"article_read_time.png\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Article category distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles[DEFAULT_CATEGORY_STR_COL].value_counts(sort=True).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate = {\n",
    "    \"nyheder\": \"NWS\",  # news\n",
    "    #\n",
    "    \"underholdning\": \"ENT\",  # entertainment\n",
    "    \"musik\": \"ENT\",  # entertainment\n",
    "    #\n",
    "    \"krimi\": \"CRM\",  # crime\n",
    "    #\n",
    "    \"sport\": \"SPT\",  # sports\n",
    "    #\n",
    "    \"forbrug\": \"LFS\",  # Lifestyle\n",
    "    \"biler\": \"LFS\",  # Lifestyle\n",
    "    \"ferie\": \"LFS\",  # Lifestyle\n",
    "    \"vin\": \"LFS\",  # Lifestyle\n",
    "    #\n",
    "    \"sex_og_samliv\": \"SRL\",  # S&R\n",
    "    #\n",
    "    \"nationen\": \"OPN\",  # Opinion\n",
    "    \"opinionen\": \"OPN\",  # Opinion\n",
    "}\n",
    "df_category = (\n",
    "    df_articles[DEFAULT_CATEGORY_STR_COL]\n",
    "    .replace(translate, default=\"MSC\")\n",
    "    .value_counts(sort=True)\n",
    "    .with_columns(pl.col(\"count\") / pl.col(\"count\").sum())\n",
    ")\n",
    "df_category.with_columns(pl.col(\"count\").cum_sum().name.suffix(\"_cum_sum\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_bar_plot(\n",
    "    df_category.to_pandas(),\n",
    "    x_col=DEFAULT_CATEGORY_STR_COL,\n",
    "    y_col=\"count\",\n",
    "    y_as_percentage=True,\n",
    "    colors=sns.color_palette(n_colors=df_category.shape[0]),\n",
    "    fontsize=75,\n",
    "    rotation=45,\n",
    "    save_path=PLOT_PATH.joinpath(CATEGORY_DIST_NAME + \".png\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate-list distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_aids = (\n",
    "    df_behaviors_test_ba.filter(pl.col(DEFAULT_IS_BEYOND_ACCURACY_COL))\n",
    "    .select(pl.col(DEFAULT_INVIEW_ARTICLES_COL).first().explode())\n",
    "    .collect()\n",
    ")[DEFAULT_INVIEW_ARTICLES_COL].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_category_ba = (\n",
    "    df_articles.filter(pl.col(DEFAULT_ARTICLE_ID_COL).is_in(ba_aids))[\n",
    "        DEFAULT_CATEGORY_STR_COL\n",
    "    ]\n",
    "    .replace(translate, default=\"MSC\")\n",
    "    .value_counts(sort=True)\n",
    "    .with_columns(pl.col(\"count\") / pl.col(\"count\").sum())\n",
    ")\n",
    "df_category_ba.with_columns(pl.col(\"count\").cum_sum().name.suffix(\"_cum_sum\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_bar_plot(\n",
    "    df_category_ba.to_pandas(),\n",
    "    x_col=DEFAULT_CATEGORY_STR_COL,\n",
    "    y_col=\"count\",\n",
    "    y_as_percentage=True,\n",
    "    colors=sns.color_palette(n_colors=df_category.shape[0]),\n",
    "    fontsize=75,\n",
    "    rotation=45,\n",
    "    save_path=PLOT_PATH.joinpath(CATEGORY_DIST_NAME + \"_ba\" + \".png\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eb-nerd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
