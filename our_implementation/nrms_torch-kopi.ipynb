{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NRMS Model (PyTorch Version)\n",
    "\n",
    "This notebook demonstrates how to build, train, and evaluate a Neural News Recommendation Model (NRMS) using PyTorch instead of TensorFlow. We will still attempt to use `ebrec` utilities for data loading and evaluation where possible.\n",
    "\n",
    "## Overview\n",
    "\n",
    "We will:\n",
    "1.  Setup: Import necessary libraries and define hyperparameters.\n",
    "2.  Define NRMS Model Components: Implement custom layers and the NRMS model architecture.\n",
    "3.  Data Loading and Preparation: Load and preprocess the dataset.\n",
    "4.  Article Embeddings: Generate embeddings for articles using a pre-trained transformer model.\n",
    "5.  Batch and Shape Data: Create PyTorch datasets and dataloaders.\n",
    "6.  Training the Model: Train the NRMS model.\n",
    "7.  Evaluation on Test Set: Evaluate the trained model.\n",
    "8.  Submission File: Generate a submission file with predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinmoore/anaconda3/envs/eb-nerd/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from ebrec.utils._behaviors import ebnerd_from_path, create_binary_labels_column, sampling_strategy_wu2019\n",
    "from ebrec.utils._articles import convert_text2encoding_with_transformers, create_article_id_to_value_mapping\n",
    "from ebrec.utils._polars import concat_str_columns\n",
    "from ebrec.utils._constants import DEFAULT_USER_COL, DEFAULT_IMPRESSION_ID_COL, DEFAULT_IMPRESSION_TIMESTAMP_COL, \\\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL, DEFAULT_CLICKED_ARTICLES_COL, DEFAULT_INVIEW_ARTICLES_COL\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HParams:\n",
    "    title_size = 30\n",
    "    history_size = 20\n",
    "    head_num = 12\n",
    "    head_dim = 64\n",
    "    attention_hidden_dim = 200\n",
    "    dropout = 0.2\n",
    "    learning_rate = 1e-4\n",
    "    batch_size = 32\n",
    "    transformer_model_name = \"facebookai/xlm-roberta-base\"\n",
    "    data_fraction = 0.01\n",
    "    sampling_npratio = 4\n",
    "    sampling_shuffle = True\n",
    "    sampling_with_replacement = True\n",
    "    sampling_seed = 32\n",
    "\n",
    "hparams = HParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, head_num, head_dim, embedding_dim):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.head_num = head_num\n",
    "        self.head_dim = head_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.output_dim = head_num * head_dim\n",
    "        self.WQ = nn.Linear(embedding_dim, self.output_dim)\n",
    "        self.WK = nn.Linear(embedding_dim, self.output_dim)\n",
    "        self.WV = nn.Linear(embedding_dim, self.output_dim)\n",
    "        self.dropout = nn.Dropout(hparams.dropout)\n",
    "\n",
    "    def forward(self, Q_seq, K_seq, V_seq):\n",
    "        Q = self.WQ(Q_seq)  # [N, L, output_dim]\n",
    "        K = self.WK(K_seq)\n",
    "        V = self.WV(V_seq)\n",
    "        \n",
    "        N, L, _ = Q.size()\n",
    "        Q = Q.view(N, L, self.head_num, self.head_dim).transpose(1, 2)  # [N, head_num, L, head_dim]\n",
    "        K = K.view(N, L, self.head_num, self.head_dim).transpose(1, 2)\n",
    "        V = V.view(N, L, self.head_num, self.head_dim).transpose(1, 2)\n",
    "        \n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / np.sqrt(self.head_dim)  # [N, head_num, L, L]\n",
    "        attn = torch.softmax(scores, dim=-1)\n",
    "        attn = self.dropout(attn)\n",
    "        output = torch.matmul(attn, V)  # [N, head_num, L, head_dim]\n",
    "        output = output.transpose(1, 2).contiguous().view(N, L, self.output_dim)  # [N, L, head_num*head_dim]\n",
    "        return output\n",
    "    \n",
    "class AttLayer(nn.Module):\n",
    "    def __init__(self, attention_hidden_dim):\n",
    "        super(AttLayer, self).__init__()\n",
    "        self.W = nn.Linear(hparams.head_num * hparams.head_dim, attention_hidden_dim)\n",
    "        self.q = nn.Linear(attention_hidden_dim, 1, bias=False)\n",
    "        self.dropout = nn.Dropout(hparams.dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn = torch.tanh(self.W(x))  # [N, L, attention_hidden_dim]\n",
    "        attn = self.q(attn).squeeze(-1)  # [N, L]\n",
    "        attn = torch.softmax(attn, dim=1).unsqueeze(-1)  # [N, L, 1]\n",
    "        output = torch.sum(x * attn, dim=1)  # [N, head_num*head_dim]\n",
    "        output = self.dropout(output)\n",
    "        return output\n",
    "\n",
    "class NRMSModel(nn.Module):\n",
    "    def __init__(self, hparams, word_embeddings):\n",
    "        super(NRMSModel, self).__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(\n",
    "            torch.FloatTensor(word_embeddings), freeze=False\n",
    "        )\n",
    "        self.dropout = nn.Dropout(hparams.dropout)\n",
    "\n",
    "        # News Encoder\n",
    "        self.news_self_att = SelfAttention(hparams.head_num, hparams.head_dim, embedding_dim=768)\n",
    "        self.news_att = AttLayer(hparams.attention_hidden_dim)\n",
    "\n",
    "        # User Encoder\n",
    "        self.user_self_att = SelfAttention(hparams.head_num, hparams.head_dim, embedding_dim=768)\n",
    "        self.user_att = AttLayer(hparams.attention_hidden_dim)\n",
    "\n",
    "    def encode_news(self, news_input):\n",
    "        x = self.embedding(news_input)  # [N, L, D=768]\n",
    "        x = self.dropout(x)\n",
    "        x = self.news_self_att(x, x, x)  # [N, L, head_num*head_dim=768]\n",
    "        x = self.news_att(x)             # [N, head_num*head_dim=768]\n",
    "        return x\n",
    "\n",
    "    def encode_user(self, history_input):\n",
    "        N, H, L = history_input.size()\n",
    "        history_input = history_input.view(N * H, L)  # [N*H, L]\n",
    "        news_vectors = self.encode_news(history_input)  # [N*H, 768]\n",
    "        news_vectors = news_vectors.view(N, H, -1)     # [N, H, 768]\n",
    "        user_vector = self.user_self_att(news_vectors, news_vectors, news_vectors)  # [N, H, 768]\n",
    "        user_vector = self.user_att(user_vector)      # [N, 768]\n",
    "        return user_vector\n",
    "\n",
    "    def forward(self, his_input, pred_input):\n",
    "        user_vector = self.encode_user(his_input)      # [N, 768]\n",
    "        N, M, L = pred_input.size()\n",
    "        pred_input = pred_input.view(N * M, L)        # [N*M, L]\n",
    "        news_vectors = self.encode_news(pred_input)    # [N*M, 768]\n",
    "        news_vectors = news_vectors.view(N, M, -1)    # [N, M, 768]\n",
    "        scores = torch.bmm(news_vectors, user_vector.unsqueeze(2)).squeeze(-1)  # [N, M]\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NRMSDataset(Dataset):\n",
    "    def __init__(self, df, article_mapping, title_size):\n",
    "        \"\"\"\n",
    "        Initializes the dataset by mapping article IDs to their token representations.\n",
    "\n",
    "        Args:\n",
    "            df (pl.DataFrame): DataFrame containing history and candidate tokens.\n",
    "            article_mapping (dict): Mapping from article IDs to token lists.\n",
    "            title_size (int): Fixed size for title tokens.\n",
    "        \"\"\"\n",
    "        self.history = df[\"history_tokens\"].to_list()\n",
    "        self.candidates = df[\"candidate_tokens\"].to_list()\n",
    "        self.labels = df[\"labels\"].to_list()\n",
    "        self.article_mapping = article_mapping\n",
    "        self.title_size = title_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        his_tokens = self.history[idx]\n",
    "        pred_tokens = self.candidates[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        his_ids = torch.tensor(his_tokens, dtype=torch.long)\n",
    "        pred_ids = torch.tensor(pred_tokens, dtype=torch.long)\n",
    "        y = torch.tensor(label, dtype=torch.float32)\n",
    "        return his_ids, pred_ids, y\n",
    "\n",
    "def nrms_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function to handle variable number of candidates per sample.\n",
    "    \n",
    "    Args:\n",
    "        batch (list of tuples): Each tuple contains (history_tokens, candidate_tokens, labels).\n",
    "    \n",
    "    Returns:\n",
    "        dict: Padded and batched history, candidates, labels, and masks.\n",
    "    \"\"\"\n",
    "    histories, candidates, labels = zip(*batch)\n",
    "    \n",
    "    # Convert histories to tensor: [batch_size, history_size, title_size]\n",
    "    histories = torch.stack(histories)\n",
    "    \n",
    "    # Find the maximum number of candidates in the batch\n",
    "    max_candidates = max([cand.size(0) for cand in candidates])\n",
    "    \n",
    "    # Pad candidates to have the same number within the batch\n",
    "    padded_candidates = []\n",
    "    candidate_masks = []\n",
    "    for cand in candidates:\n",
    "        num_cands = cand.size(0)\n",
    "        if num_cands < max_candidates:\n",
    "            pad_size = max_candidates - num_cands\n",
    "            padded_cand = torch.cat([cand, torch.zeros(pad_size, cand.size(1), dtype=torch.long)])\n",
    "            mask = torch.cat([torch.ones(num_cands, dtype=torch.bool), torch.zeros(pad_size, dtype=torch.bool)])\n",
    "        else:\n",
    "            padded_cand = cand[:max_candidates]\n",
    "            mask = torch.ones(max_candidates, dtype=torch.bool)\n",
    "        padded_candidates.append(padded_cand)\n",
    "        candidate_masks.append(mask)\n",
    "    \n",
    "    # Stack candidates and masks: [batch_size, max_candidates, title_size], [batch_size, max_candidates]\n",
    "    padded_candidates = torch.stack(padded_candidates)\n",
    "    candidate_masks = torch.stack(candidate_masks)\n",
    "    \n",
    "    # Convert labels to tensor and pad similarly\n",
    "    padded_labels = []\n",
    "    for label in labels:\n",
    "        num_cands = label.size(0)\n",
    "        if num_cands < max_candidates:\n",
    "            pad_size = max_candidates - num_cands\n",
    "            padded_label = torch.cat([label, torch.zeros(pad_size, dtype=torch.float32)])\n",
    "        else:\n",
    "            padded_label = label[:max_candidates]\n",
    "        padded_labels.append(padded_label)\n",
    "    padded_labels = torch.stack(padded_labels)\n",
    "    \n",
    "    return {\n",
    "        'history': histories,               # [batch_size, history_size, title_size]\n",
    "        'candidates': padded_candidates,    # [batch_size, max_candidates, title_size]\n",
    "        'labels': padded_labels,            # [batch_size, max_candidates]\n",
    "        'candidate_masks': candidate_masks  # [batch_size, max_candidates]\n",
    "    }\n",
    "\n",
    "def create_dataloader(df, article_mapping, title_size, batch_size=32, shuffle=False, num_workers=0):\n",
    "    \"\"\"\n",
    "    Creates a DataLoader for the NRMS dataset with a custom collate function.\n",
    "    \n",
    "    Args:\n",
    "        df (pl.DataFrame): DataFrame containing history and candidate tokens.\n",
    "        article_mapping (dict): Mapping from article IDs to token lists.\n",
    "        title_size (int): Fixed size for title tokens.\n",
    "        batch_size (int): Number of samples per batch.\n",
    "        shuffle (bool): Whether to shuffle the data.\n",
    "        num_workers (int): Number of subprocesses for data loading.\n",
    "    \n",
    "    Returns:\n",
    "        DataLoader: PyTorch DataLoader.\n",
    "    \"\"\"\n",
    "    dataset = NRMSDataset(df, article_mapping, title_size)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True if torch.cuda.is_available() else False,\n",
    "        collate_fn=nrms_collate_fn\n",
    "    )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate counts per sample (min expected: 1):\n",
      "5 candidates: 2008 samples\n",
      "Candidate counts per sample (min expected: 1):\n",
      "5 candidates: 334 samples\n"
     ]
    }
   ],
   "source": [
    "# Data paths\n",
    "DATA_PATH = Path(\"~/Git Repositories/ebnerd-benchmark/data\").expanduser()\n",
    "DATA_SPLIT = \"ebnerd_small\"\n",
    "COLUMNS = [\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "    DEFAULT_IMPRESSION_TIMESTAMP_COL,\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "]\n",
    "\n",
    "# Load and preprocess data\n",
    "df = (\n",
    "    ebnerd_from_path(\n",
    "        DATA_PATH.joinpath(DATA_SPLIT, \"train\"),\n",
    "        history_size=hparams.history_size,\n",
    "        padding=0,\n",
    "    )\n",
    "    .select(COLUMNS)\n",
    "    .pipe(\n",
    "        sampling_strategy_wu2019,\n",
    "        npratio=hparams.sampling_npratio,\n",
    "        shuffle=hparams.sampling_shuffle,\n",
    "        with_replacement=hparams.sampling_with_replacement,\n",
    "        seed=hparams.sampling_seed,\n",
    "    )\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=hparams.data_fraction)\n",
    ")\n",
    "\n",
    "# Load articles data\n",
    "df_articles = pl.read_parquet(DATA_PATH.joinpath(DATA_SPLIT, \"articles.parquet\"))\n",
    "\n",
    "# Load transformer model and tokenizer\n",
    "transformer_model = AutoModel.from_pretrained(hparams.transformer_model_name)\n",
    "transformer_tokenizer = AutoTokenizer.from_pretrained(hparams.transformer_model_name)\n",
    "transformer_model.eval()\n",
    "\n",
    "# Get word embeddings\n",
    "word_embeddings = transformer_model.get_input_embeddings().weight.detach().numpy()\n",
    "\n",
    "# Prepare article mappings\n",
    "df_articles, cat_col = concat_str_columns(df_articles, columns=[\"subtitle\", \"title\"])\n",
    "df_articles, token_col_title = convert_text2encoding_with_transformers(\n",
    "    df_articles, transformer_tokenizer, cat_col, max_length=hparams.title_size\n",
    ")\n",
    "article_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, value_col=token_col_title\n",
    ")\n",
    "\n",
    "# Fix article mapping values\n",
    "article_mapping = {\n",
    "    k: v[0] if isinstance(v, list) and len(v) > 0 else [0] * hparams.title_size\n",
    "    for k, v in article_mapping.items()\n",
    "}\n",
    "\n",
    "# Splitting\n",
    "dt_split = df[DEFAULT_IMPRESSION_TIMESTAMP_COL].max() - datetime.timedelta(days=1)\n",
    "df_train = df.filter(pl.col(DEFAULT_IMPRESSION_TIMESTAMP_COL) < dt_split)\n",
    "df_validation = df.filter(pl.col(DEFAULT_IMPRESSION_TIMESTAMP_COL) >= dt_split)\n",
    "\n",
    "# Transforming with Variable Candidates\n",
    "def transform_df(df, article_mapping, title_size):\n",
    "    \"\"\"\n",
    "    Transforms the DataFrame by mapping article IDs to tokens.\n",
    "    \n",
    "    Args:\n",
    "        df (pl.DataFrame): Input DataFrame.\n",
    "        article_mapping (dict): Mapping from article IDs to token lists.\n",
    "        title_size (int): Fixed size for title tokens.\n",
    "    \n",
    "    Returns:\n",
    "        pl.DataFrame: Transformed DataFrame with history_tokens and candidate_tokens.\n",
    "    \"\"\"\n",
    "    pad_value = [0] * title_size\n",
    "    df = df.with_columns(\n",
    "        pl.col(DEFAULT_HISTORY_ARTICLE_ID_COL).map_elements(\n",
    "            lambda history: [\n",
    "                article_mapping.get(aid, pad_value) for aid in history\n",
    "            ]\n",
    "        ).alias(\"history_tokens\")\n",
    "    )\n",
    "    \n",
    "    df = df.with_columns(\n",
    "        pl.col(DEFAULT_INVIEW_ARTICLES_COL).map_elements(\n",
    "            lambda candidates: [\n",
    "                article_mapping.get(aid, pad_value) for aid in candidates\n",
    "            ]\n",
    "        ).alias(\"candidate_tokens\")\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_train = transform_df(df_train, article_mapping, hparams.title_size)\n",
    "df_validation = transform_df(df_validation, article_mapping, hparams.title_size)\n",
    "\n",
    "# Verify candidate counts after transformation\n",
    "def verify_candidate_counts(df, expected_min=1):\n",
    "    candidate_counts = df[\"candidate_tokens\"].map_elements(len).to_numpy()\n",
    "    unique_counts, counts = np.unique(candidate_counts, return_counts=True)\n",
    "    print(f\"Candidate counts per sample (min expected: {expected_min}):\")\n",
    "    for uc, c in zip(unique_counts, counts):\n",
    "        print(f\"{uc} candidates: {c} samples\")\n",
    "\n",
    "verify_candidate_counts(df_train, expected_min=1)\n",
    "verify_candidate_counts(df_validation, expected_min=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 1.6163\n",
      "Epoch 2/3, Loss: 1.6219\n",
      "Epoch 3/3, Loss: 1.6190\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = NRMSModel(hparams, word_embeddings)\n",
    "\n",
    "# Move model to device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = create_dataloader(\n",
    "    df_train,\n",
    "    article_mapping,\n",
    "    hparams.title_size,\n",
    "    batch_size=hparams.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0  # Set to >0 if NRMSDataset is in a separate module\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader(\n",
    "    df_validation,\n",
    "    article_mapping,\n",
    "    hparams.title_size,\n",
    "    batch_size=hparams.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "# Training loop\n",
    "def train_model(model, train_loader, hparams, num_epochs):\n",
    "    criterion = nn.CrossEntropyLoss(reduction='none')  # We'll handle reduction manually\n",
    "    optimizer = optim.Adam(model.parameters(), lr=hparams.learning_rate)\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            his_input = batch['history'].to(device)               # [N, history_size, title_size]\n",
    "            pred_input = batch['candidates'].to(device)           # [N, max_candidates, title_size]\n",
    "            labels = batch['labels'].to(device)                   # [N, max_candidates]\n",
    "            candidate_masks = batch['candidate_masks'].to(device) # [N, max_candidates]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            scores = model(his_input, pred_input)                # [N, max_candidates]\n",
    "            \n",
    "            # Compute loss\n",
    "            # CrossEntropyLoss expects class indices, so convert labels\n",
    "            # Since each sample can have multiple positives, adjust accordingly\n",
    "            # For simplicity, assume each sample has exactly one positive as per earlier steps\n",
    "            # If multiple positives are possible, consider using BCEWithLogitsLoss\n",
    "            targets = torch.argmax(labels, dim=1)                 # [N]\n",
    "            \n",
    "            # Apply mask: Ensure that the target is not a padded candidate\n",
    "            # Find the actual target indices\n",
    "            valid = candidate_masks[torch.arange(labels.size(0)), targets]\n",
    "            # If not valid, set target to a default class (e.g., 0), and mask the loss\n",
    "            adjusted_targets = targets.clone()\n",
    "            adjusted_targets[~valid] = 0  # Assuming class 0 is padding\n",
    "            \n",
    "            # Compute per-sample loss\n",
    "            loss_per_sample = criterion(scores, adjusted_targets)   # [N]\n",
    "            # Mask the loss: Zero out loss where target was padded\n",
    "            loss_per_sample = loss_per_sample * valid.float()\n",
    "            # Compute average loss\n",
    "            loss = loss_per_sample.sum() / valid.sum()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 3\n",
    "\n",
    "train_model(model, train_loader, hparams, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 334\n",
      "Valid samples (exactly one positive): 334\n",
      "Invalid samples (not exactly one positive): 0\n",
      "Evaluation Results:\n",
      "auc: 0.5000\n",
      "mrr: 0.4620\n",
      "ndcg@5: 0.5936\n",
      "ndcg@10: 0.5936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'auc': 0.5,\n",
       " 'mrr': 0.4620259481037924,\n",
       " 'ndcg@5': 0.5935963546212292,\n",
       " 'ndcg@10': 0.5935963546212292}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Define evaluation metrics\n",
    "def calculate_mrr(y_true, y_scores):\n",
    "    \"\"\"\n",
    "    Calculates Mean Reciprocal Rank (MRR).\n",
    "    \n",
    "    Args:\n",
    "        y_true (np.ndarray): True labels, shape [num_samples, num_candidates].\n",
    "        y_scores (np.ndarray): Prediction scores, shape [num_samples, num_candidates].\n",
    "    \n",
    "    Returns:\n",
    "        float: MRR score.\n",
    "    \"\"\"\n",
    "    ranks = []\n",
    "    for true, scores in zip(y_true, y_scores):\n",
    "        sorted_indices = np.argsort(scores)[::-1]\n",
    "        try:\n",
    "            rank = np.where(true[sorted_indices] == 1)[0][0] + 1\n",
    "            ranks.append(1.0 / rank)\n",
    "        except IndexError:\n",
    "            ranks.append(0.0)\n",
    "    return np.mean(ranks)\n",
    "\n",
    "def calculate_ndcg(y_true, y_scores, k=10):\n",
    "    \"\"\"\n",
    "    Calculates Normalized Discounted Cumulative Gain (NDCG) at rank k.\n",
    "\n",
    "    Args:\n",
    "        y_true (np.ndarray): True labels, shape [num_samples, num_candidates].\n",
    "        y_scores (np.ndarray): Prediction scores, shape [num_samples, num_candidates].\n",
    "        k (int): Rank at which to calculate NDCG.\n",
    "\n",
    "    Returns:\n",
    "        float: NDCG@k score.\n",
    "    \"\"\"\n",
    "    ndcgs = []\n",
    "    for true, scores in zip(y_true, y_scores):\n",
    "        sorted_indices = np.argsort(scores)[::-1]\n",
    "        dcg = 0.0\n",
    "        for i in range(min(k, len(true))):\n",
    "            idx = sorted_indices[i]\n",
    "            if idx < len(true) and true[idx] == 1:\n",
    "                dcg += 1.0 / np.log2(i + 2)\n",
    "        num_relevant = np.sum(true)\n",
    "        idcg = sum([1.0 / np.log2(i + 2) for i in range(min(k, num_relevant))])\n",
    "        ndcgs.append(dcg / idcg if idcg > 0 else 0.0)\n",
    "    return np.mean(ndcgs)\n",
    "\n",
    "def evaluate_model_pytorch(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Evaluates the NRMS model on the provided dataloader and computes metrics.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Trained NRMS model.\n",
    "        dataloader (DataLoader): DataLoader for the validation/test dataset.\n",
    "        device (torch.device): Device to perform computations on.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing evaluation metrics.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_scores = []\n",
    "    all_labels = []\n",
    "    all_masks = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            his_input = batch['history'].to(device)               # [N, history_size, title_size]\n",
    "            pred_input = batch['candidates'].to(device)           # [N, max_candidates, title_size]\n",
    "            labels = batch['labels'].to(device)                   # [N, max_candidates]\n",
    "            candidate_masks = batch['candidate_masks'].to(device) # [N, max_candidates]\n",
    "            \n",
    "            scores = model(his_input, pred_input)                # [N, max_candidates]\n",
    "            all_scores.append(scores.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            # Optionally, if needed for metrics that consider masks:\n",
    "            # all_masks.append(candidate_masks.cpu().numpy())\n",
    "    \n",
    "    # Concatenate all batches\n",
    "    all_scores = np.vstack(all_scores)  # [num_samples, max_candidates]\n",
    "    all_labels = np.vstack(all_labels)  # [num_samples, max_candidates]\n",
    "    \n",
    "    # Ensure binary labels\n",
    "    all_labels = (all_labels >= 1).astype(int)\n",
    "    \n",
    "    # Handle samples with exactly one positive label\n",
    "    valid_indices = np.where(all_labels.sum(axis=1) == 1)[0]\n",
    "    \n",
    "    num_total = all_labels.shape[0]\n",
    "    num_valid = valid_indices.shape[0]\n",
    "    num_invalid = num_total - num_valid\n",
    "    print(f\"Total samples: {num_total}\")\n",
    "    print(f\"Valid samples (exactly one positive): {num_valid}\")\n",
    "    print(f\"Invalid samples (not exactly one positive): {num_invalid}\")\n",
    "    \n",
    "    if num_valid == 0:\n",
    "        print(\"No valid samples with exactly one positive label. Evaluation cannot be performed.\")\n",
    "        return {}\n",
    "    \n",
    "    # Filter valid samples\n",
    "    valid_scores = all_scores[valid_indices]\n",
    "    valid_labels = all_labels[valid_indices]\n",
    "    \n",
    "    # Convert scores to probabilities using softmax\n",
    "    probabilities = torch.softmax(torch.tensor(valid_scores), dim=1).numpy()\n",
    "    \n",
    "    # Compute ROC AUC (one-vs-rest for multi-class)\n",
    "    auc = roc_auc_score(valid_labels, probabilities, average='macro', multi_class='ovr')\n",
    "    \n",
    "    # Compute MRR\n",
    "    mrr = calculate_mrr(valid_labels, valid_scores)\n",
    "    \n",
    "    # Compute NDCG@5 and NDCG@10\n",
    "    ndcg_5 = calculate_ndcg(valid_labels, valid_scores, k=5)\n",
    "    ndcg_10 = calculate_ndcg(valid_labels, valid_scores, k=10)\n",
    "    \n",
    "    metrics = {\n",
    "        \"auc\": auc,\n",
    "        \"mrr\": mrr,\n",
    "        \"ndcg@5\": ndcg_5,\n",
    "        \"ndcg@10\": ndcg_10\n",
    "    }\n",
    "    \n",
    "    print(\"Evaluation Results:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model_pytorch(model, val_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eb-nerd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
