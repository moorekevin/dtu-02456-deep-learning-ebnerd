{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NRMS Model (PyTorch Version)\n",
    "\n",
    "This notebook demonstrates how to build, train, and evaluate a Neural News Recommendation Model (NRMS) using PyTorch instead of TensorFlow. We will still attempt to use `ebrec` utilities for data loading and evaluation where possible.\n",
    "\n",
    "## Overview\n",
    "\n",
    "We will:\n",
    "1.  Setup: Import necessary libraries and define hyperparameters.\n",
    "2.  Define NRMS Model Components: Implement custom layers and the NRMS model architecture.\n",
    "3.  Data Loading and Preparation: Load and preprocess the dataset.\n",
    "4.  Article Embeddings: Generate embeddings for articles using a pre-trained transformer model.\n",
    "5.  Batch and Shape Data: Create PyTorch datasets and dataloaders.\n",
    "6.  Training the Model: Train the NRMS model.\n",
    "7.  Evaluation on Test Set: Evaluate the trained model.\n",
    "8.  Submission File: Generate a submission file with predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinmoore/anaconda3/envs/eb-nerd/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from ebrec.utils._behaviors import (\n",
    "  ebnerd_from_path,\n",
    "  create_binary_labels_column,\n",
    "  sampling_strategy_wu2019,\n",
    ")\n",
    "from ebrec.utils._articles import (\n",
    "  convert_text2encoding_with_transformers,\n",
    "  create_article_id_to_value_mapping,\n",
    ")\n",
    "from ebrec.utils._nlp import get_transformers_word_embeddings\n",
    "from ebrec.utils._polars import concat_str_columns\n",
    "from ebrec.utils._constants import *\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Hyperparameters\n",
    "class HParams:\n",
    "  title_size = 30\n",
    "  history_size = 20\n",
    "  head_num = 16\n",
    "  head_dim = 16\n",
    "  attention_hidden_dim = 200\n",
    "  dropout = 0.2\n",
    "  learning_rate = 1e-4\n",
    "\n",
    "hparams = HParams()\n",
    "\n",
    "# Transformer model name\n",
    "TRANSFORMER_MODEL_NAME = \"FacebookAI/xlm-roberta-base\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "  def __init__(self, head_num, head_dim):\n",
    "    super().__init__()\n",
    "    self.head_num = head_num\n",
    "    self.head_dim = head_dim\n",
    "    self.output_dim = head_num * head_dim\n",
    "    self.WQ = None\n",
    "    self.WK = None\n",
    "    self.WV = None\n",
    "    self.initialized = False\n",
    "\n",
    "  def _initialize(self, input_dim):\n",
    "    self.WQ = nn.Parameter(torch.empty(input_dim, self.output_dim))\n",
    "    self.WK = nn.Parameter(torch.empty(input_dim, self.output_dim))\n",
    "    self.WV = nn.Parameter(torch.empty(input_dim, self.output_dim))\n",
    "    nn.init.xavier_uniform_(self.WQ)\n",
    "    nn.init.xavier_uniform_(self.WK)\n",
    "    nn.init.xavier_uniform_(self.WV)\n",
    "    self.initialized = True\n",
    "\n",
    "  def forward(self, Q_seq, K_seq, V_seq):\n",
    "    if not self.initialized:\n",
    "      self._initialize(Q_seq.size(-1))\n",
    "\n",
    "    Q = torch.matmul(Q_seq, self.WQ)\n",
    "    K = torch.matmul(K_seq, self.WK)\n",
    "    V = torch.matmul(V_seq, self.WV)\n",
    "\n",
    "    N, L, _ = Q.size()\n",
    "    Q = Q.view(N, L, self.head_num, self.head_dim).permute(0, 2, 1, 3)\n",
    "    K = K.view(N, L, self.head_num, self.head_dim).permute(0, 2, 1, 3)\n",
    "    V = V.view(N, L, self.head_num, self.head_dim).permute(0, 2, 1, 3)\n",
    "\n",
    "    A = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(self.head_dim)\n",
    "    A = torch.softmax(A, dim=-1)\n",
    "    O = torch.matmul(A, V)\n",
    "\n",
    "    O = O.permute(0, 2, 1, 3).contiguous().view(N, L, self.output_dim)\n",
    "    return O\n",
    "  \n",
    "class AttLayer(nn.Module):\n",
    "  def __init__(self, attention_hidden_dim):\n",
    "    super().__init__()\n",
    "    self.attention_hidden_dim = attention_hidden_dim\n",
    "    self.W = None\n",
    "    self.q = None\n",
    "    self.initialized = False\n",
    "\n",
    "  def _initialize(self, input_dim):\n",
    "    self.W = nn.Linear(input_dim, self.attention_hidden_dim)\n",
    "    self.q = nn.Linear(self.attention_hidden_dim, 1, bias=False)\n",
    "    self.initialized = True\n",
    "\n",
    "  def forward(self, x):\n",
    "    if not self.initialized:\n",
    "      self._initialize(x.size(-1))\n",
    "    attention = torch.tanh(self.W(x))\n",
    "    attention = self.q(attention).squeeze(-1)\n",
    "    att_weight = torch.softmax(attention, dim=1).unsqueeze(-1)\n",
    "    output = torch.sum(x * att_weight, dim=1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NRMS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NRMSModel(nn.Module):\n",
    "  def __init__(self, hparams, word_embeddings):\n",
    "    super().__init__()\n",
    "    self.hparams = hparams\n",
    "    self.embedding = nn.Embedding.from_pretrained(\n",
    "      torch.FloatTensor(word_embeddings), freeze=False\n",
    "    )\n",
    "    self.dropout = nn.Dropout(hparams.dropout)\n",
    "\n",
    "    # News Encoder\n",
    "    self.news_self_att = SelfAttention(hparams.head_num, hparams.head_dim)\n",
    "    self.news_att = AttLayer(hparams.attention_hidden_dim)\n",
    "\n",
    "    # User Encoder\n",
    "    self.user_self_att = SelfAttention(hparams.head_num, hparams.head_dim)\n",
    "    self.user_att = AttLayer(hparams.attention_hidden_dim)\n",
    "\n",
    "  def encode_news(self, news_input):\n",
    "    x = self.embedding(news_input)\n",
    "    x = self.dropout(x)\n",
    "    x = self.news_self_att(x, x, x)\n",
    "    x = self.news_att(x)\n",
    "    return x\n",
    "\n",
    "  def encode_user(self, history_input):\n",
    "    N, H, L = history_input.size()\n",
    "    history_input = history_input.view(N * H, L)\n",
    "    news_vectors = self.encode_news(history_input)\n",
    "    news_vectors = news_vectors.view(N, H, -1)\n",
    "    user_vector = self.user_self_att(news_vectors, news_vectors, news_vectors)\n",
    "    user_vector = self.user_att(user_vector)\n",
    "    return user_vector\n",
    "\n",
    "  def forward(self, his_input, pred_input):\n",
    "    user_vector = self.encode_user(his_input)           # Shape: [N, D]\n",
    "    N, M, L = pred_input.size()\n",
    "    pred_input = pred_input.view(N * M, L)\n",
    "    news_vectors = self.encode_news(pred_input)         # Shape: [N*M, D]\n",
    "    news_vectors = news_vectors.view(N, M, -1)          # Shape: [N, M, D]\n",
    "    user_vector = user_vector.unsqueeze(2)              # Shape: [N, D, 1]\n",
    "    scores = torch.bmm(news_vectors, user_vector).squeeze(-1)  # Shape: [N, M]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NRMSDataset(Dataset):\n",
    "  def __init__(self, df):\n",
    "    self.history = df[\"history_tokens\"].to_list()\n",
    "    self.candidates = df[\"candidate_tokens\"].to_list()\n",
    "    self.labels = df[\"labels\"].to_list()\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.labels)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    his_ids = torch.tensor(self.history[idx], dtype=torch.long)\n",
    "    pred_ids = torch.tensor(self.candidates[idx], dtype=torch.long)\n",
    "    y = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "    return his_ids, pred_ids, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths\n",
    "PATH = Path(\"~/Git Repositories/ebnerd-benchmark/data\").expanduser()\n",
    "DATASPLIT = \"ebnerd_small\"\n",
    "COLUMNS = [\n",
    "  DEFAULT_USER_COL,\n",
    "  DEFAULT_IMPRESSION_ID_COL,\n",
    "  DEFAULT_IMPRESSION_TIMESTAMP_COL,\n",
    "  DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "  DEFAULT_CLICKED_ARTICLES_COL,\n",
    "  DEFAULT_INVIEW_ARTICLES_COL,\n",
    "]\n",
    "\n",
    "# Load and preprocess data\n",
    "FRACTION = 0.01\n",
    "df = (\n",
    "  ebnerd_from_path(\n",
    "    PATH.joinpath(DATASPLIT, \"train\"),\n",
    "    history_size=hparams.history_size,\n",
    "    padding=0,\n",
    "  )\n",
    "  .select(COLUMNS)\n",
    "  .pipe(\n",
    "    sampling_strategy_wu2019,\n",
    "    npratio=4,\n",
    "    shuffle=True,\n",
    "    with_replacement=True,\n",
    "    seed=123,\n",
    "  )\n",
    "  .pipe(create_binary_labels_column)\n",
    "  .sample(fraction=FRACTION)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load articles data\n",
    "df_articles = pl.read_parquet(PATH.joinpath(DATASPLIT, \"articles.parquet\"))\n",
    "\n",
    "# Load transformer model and tokenizer\n",
    "transformer_model = AutoModel.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "transformer_tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "transformer_model.eval()\n",
    "\n",
    "# Get word embeddings\n",
    "word_embeddings = transformer_model.get_input_embeddings().weight.detach().numpy()\n",
    "\n",
    "# Prepare article mappings\n",
    "df_articles, cat_col = concat_str_columns(df_articles, columns=[\"subtitle\", \"title\"])\n",
    "df_articles, token_col_title = convert_text2encoding_with_transformers(\n",
    "  df_articles, transformer_tokenizer, cat_col, max_length=hparams.title_size\n",
    ")\n",
    "article_mapping = create_article_id_to_value_mapping(\n",
    "  df=df_articles, value_col=token_col_title\n",
    ")\n",
    "\n",
    "# Fix article mapping values if necessary\n",
    "for k, v in article_mapping.items():\n",
    "  if isinstance(v, list) and len(v) > 0:\n",
    "    article_mapping[k] = v[0]\n",
    "  elif isinstance(v, list) and len(v) == 0:\n",
    "    article_mapping[k] = [0] * hparams.title_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_split = df[DEFAULT_IMPRESSION_TIMESTAMP_COL].max() - datetime.timedelta(days=1)\n",
    "df_train = df.filter(pl.col(DEFAULT_IMPRESSION_TIMESTAMP_COL) < dt_split)\n",
    "df_validation = df.filter(pl.col(DEFAULT_IMPRESSION_TIMESTAMP_COL) >= dt_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform dataframes\n",
    "def transform_df(df, article_mapping):\n",
    "  df = df.with_columns(\n",
    "    pl.col(DEFAULT_HISTORY_ARTICLE_ID_COL).map_elements(\n",
    "      lambda history: [\n",
    "        article_mapping.get(aid, [0] * hparams.title_size) for aid in history\n",
    "      ]\n",
    "    ).alias(\"history_tokens\")\n",
    "  )\n",
    "  df = df.with_columns(\n",
    "    pl.col(DEFAULT_INVIEW_ARTICLES_COL).map_elements(\n",
    "      lambda candidates: [\n",
    "        article_mapping.get(aid, [0] * hparams.title_size) for aid in candidates\n",
    "      ]\n",
    "    ).alias(\"candidate_tokens\")\n",
    "  )\n",
    "  return df\n",
    "\n",
    "# Transform training and validation data\n",
    "df_train = transform_df(df_train, article_mapping)\n",
    "df_validation = transform_df(df_validation, article_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and dataloaders\n",
    "train_dataset = NRMSDataset(df_train)\n",
    "val_dataset = NRMSDataset(df_validation)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Loss: 1.6106\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = NRMSModel(hparams, word_embeddings)\n",
    "\n",
    "# Training loop\n",
    "def train_model(model, train_loader, hparams, num_epochs):\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = optim.Adam(model.parameters(), lr=hparams.learning_rate)\n",
    "  model.train()\n",
    "  for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for his_input, pred_input, labels in train_loader:\n",
    "      optimizer.zero_grad()\n",
    "      scores = model(his_input, pred_input)\n",
    "      targets = torch.argmax(labels, dim=1)\n",
    "      loss = criterion(scores, targets)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "# Train the model\n",
    "num_epochs = 1\n",
    "train_model(model, train_loader, hparams, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 333\n",
      "Valid samples (exactly one positive): 333\n",
      "Invalid samples (not exactly one positive): 0\n",
      "Evaluation Results:\n",
      "auc: 0.5232\n",
      "mrr: 0.4907\n",
      "ndcg@5: 0.6145\n",
      "ndcg@10: 0.6145\n"
     ]
    }
   ],
   "source": [
    "# 2. Import Necessary Libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 3. Define Helper Functions for MRR and NDCG\n",
    "def calculate_mrr(y_true, y_scores):\n",
    "    \"\"\"\n",
    "    Calculates Mean Reciprocal Rank (MRR).\n",
    "    \n",
    "    Args:\n",
    "        y_true (np.ndarray): True labels, shape [num_samples, num_candidates].\n",
    "        y_scores (np.ndarray): Prediction scores, shape [num_samples, num_candidates].\n",
    "    \n",
    "    Returns:\n",
    "        float: MRR score.\n",
    "    \"\"\"\n",
    "    ranks = []\n",
    "    for true, scores in zip(y_true, y_scores):\n",
    "        sorted_indices = np.argsort(scores)[::-1]\n",
    "        try:\n",
    "            rank = np.where(true[sorted_indices] == 1)[0][0] + 1\n",
    "            ranks.append(1.0 / rank)\n",
    "        except IndexError:\n",
    "            ranks.append(0.0)\n",
    "    return np.mean(ranks)\n",
    "\n",
    "def calculate_ndcg(y_true, y_scores, k=10):\n",
    "    \"\"\"\n",
    "    Calculates Normalized Discounted Cumulative Gain (NDCG) at rank k.\n",
    "\n",
    "    Args:\n",
    "        y_true (np.ndarray): True labels, shape [num_samples, num_candidates].\n",
    "        y_scores (np.ndarray): Prediction scores, shape [num_samples, num_candidates].\n",
    "        k (int): Rank at which to calculate NDCG.\n",
    "\n",
    "    Returns:\n",
    "        float: NDCG@k score.\n",
    "    \"\"\"\n",
    "    ndcgs = []\n",
    "    for true, scores in zip(y_true, y_scores):\n",
    "        sorted_indices = np.argsort(scores)[::-1]\n",
    "        dcg = 0.0\n",
    "        for i in range(min(k, len(true))):  # Adjust loop limit\n",
    "            idx = sorted_indices[i]\n",
    "            if idx < len(true):\n",
    "                if true[idx] == 1:\n",
    "                    dcg += 1.0 / np.log2(i + 2)\n",
    "        num_relevant = np.sum(true)\n",
    "        idcg = 0.0\n",
    "        for i in range(min(k, num_relevant)):\n",
    "            idcg += 1.0 / np.log2(i + 2)\n",
    "        # Avoid division by zero\n",
    "        if idcg == 0:\n",
    "            ndcgs.append(0.0)\n",
    "        else:\n",
    "            ndcgs.append(dcg / idcg)\n",
    "    return np.mean(ndcgs)\n",
    "\n",
    "# 4. Define the Evaluation Function\n",
    "def evaluate_model_pytorch(model, dataloader, device, candidate_num=10):\n",
    "    \"\"\"\n",
    "    Evaluates the NRMS model on the provided dataloader and computes metrics.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Trained NRMS model.\n",
    "        dataloader (DataLoader): DataLoader for the validation/test dataset.\n",
    "        device (torch.device): Device to perform computations on.\n",
    "        candidate_num (int): Number of candidate articles.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing evaluation metrics.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_scores = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (his_input, pred_input, labels) in enumerate(dataloader):\n",
    "            his_input = his_input.to(device)        # Shape: [N, history_size, title_size]\n",
    "            pred_input = pred_input.to(device)      # Shape: [N, candidate_num, title_size]\n",
    "            labels = labels.to(device)              # Shape: [N, candidate_num]\n",
    "            \n",
    "            # Forward pass\n",
    "            scores = model(his_input, pred_input)   # Shape: [N, candidate_num]\n",
    "            all_scores.append(scores.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            \n",
    "            if (batch_idx + 1) % 100 == 0:\n",
    "                print(f'Processed {batch_idx+1} batches for evaluation.')\n",
    "    \n",
    "    # Concatenate all batches\n",
    "    all_scores = np.vstack(all_scores)  # Shape: [num_samples, candidate_num]\n",
    "    all_labels = np.vstack(all_labels)  # Shape: [num_samples, candidate_num]\n",
    "    \n",
    "    # Ensure binary labels\n",
    "    all_labels = (all_labels >= 1).astype(int)\n",
    "    \n",
    "    # Handle samples with exactly one positive label\n",
    "    valid_indices = np.where(all_labels.sum(axis=1) == 1)[0]\n",
    "    \n",
    "    num_total = all_labels.shape[0]\n",
    "    num_valid = valid_indices.shape[0]\n",
    "    num_invalid = num_total - num_valid\n",
    "    print(f\"Total samples: {num_total}\")\n",
    "    print(f\"Valid samples (exactly one positive): {num_valid}\")\n",
    "    print(f\"Invalid samples (not exactly one positive): {num_invalid}\")\n",
    "    \n",
    "    if num_valid == 0:\n",
    "        print(\"No valid samples with exactly one positive label. Evaluation cannot be performed.\")\n",
    "        return {}\n",
    "    \n",
    "    # Filter out invalid samples\n",
    "    valid_scores = all_scores[valid_indices]\n",
    "    valid_labels = all_labels[valid_indices]\n",
    "    \n",
    "    # Convert multi-hot labels to single label by taking argmax\n",
    "    targets = np.argmax(valid_labels, axis=1)  # Shape: [num_valid]\n",
    "    \n",
    "    # Convert scores to probabilities using softmax\n",
    "    probabilities = torch.softmax(torch.tensor(valid_scores), dim=1).numpy()\n",
    "    \n",
    "    # Compute ROC AUC (one-vs-rest for multi-class)\n",
    "    auc = roc_auc_score(valid_labels, probabilities, average='macro', multi_class='ovr')\n",
    "    \n",
    "    # Compute MRR\n",
    "    mrr = calculate_mrr(valid_labels, valid_scores)\n",
    "    \n",
    "    # Compute NDCG@5 and NDCG@10\n",
    "    ndcg_5 = calculate_ndcg(valid_labels, valid_scores, k=5)\n",
    "    ndcg_10 = calculate_ndcg(valid_labels, valid_scores, k=10)\n",
    "    \n",
    "    metrics = {\n",
    "        \"auc\": auc,\n",
    "        \"mrr\": mrr,\n",
    "        \"ndcg@5\": ndcg_5,\n",
    "        \"ndcg@10\": ndcg_10\n",
    "    }\n",
    "    \n",
    "    print(\"Evaluation Results:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# 5. Define Device and Move Model to Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# 6. Prepare the Validation/Test DataLoader\n",
    "validation_dataset = NRMSDataset(df_validation)\n",
    "validation_loader = DataLoader(\n",
    "    validation_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=0,       # Disable multiprocessing to avoid pickling issues\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# 7. Perform Evaluation\n",
    "evaluation_metrics = evaluate_model_pytorch(model, validation_loader, device, candidate_num=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eb-nerd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
