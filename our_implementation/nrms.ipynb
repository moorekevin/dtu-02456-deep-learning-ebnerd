{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NRMS Model Example\n",
    "\n",
    "This notebook demonstrates how to build, train, and evaluate a Neural News Recommendation Model (NRMS). The NRMS model uses multi-head self-attention to model user interests based on their news reading history.\n",
    "\n",
    "## Overview\n",
    "\n",
    "We will:\n",
    "\n",
    "1. Define the NRMS model architecture (including the `AttLayer2` and `SelfAttention` layers).\n",
    "2. Load and prepare the training/validation datasets.\n",
    "3. Train the model.\n",
    "4. Evaluate its performance using metrics like AUC, NDCG, and MRR.\n",
    "5. Generate a submission file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tensorflow.keras import layers, backend, callbacks, initializers\n",
    "\n",
    "GlorotUniform = initializers.GlorotUniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the NRMS Model Components\n",
    "\n",
    "The NRMS model relies on two custom layers:\n",
    "\n",
    "- **AttLayer2**: Implements a soft attention mechanism.\n",
    "- **SelfAttention**: Multi-head self-attention layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttLayer2(layers.Layer):\n",
    "    def __init__(self, dim=200, seed=0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dim = dim\n",
    "        self.seed = seed\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(\"W\", (int(input_shape[-1]), self.dim), initializer=\"glorot_uniform\")\n",
    "        self.b = self.add_weight(\"b\", (self.dim,), initializer=\"zeros\")\n",
    "        self.q = self.add_weight(\"q\", (self.dim, 1), initializer=\"glorot_uniform\")\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        attention = backend.tanh(tf.tensordot(inputs, self.W, axes=[[2],[0]]) + self.b)\n",
    "        attention = backend.dot(attention, self.q)\n",
    "        attention = backend.squeeze(attention, axis=2)\n",
    "        attention = backend.exp(attention)\n",
    "        att_weight = attention / (backend.sum(attention, axis=-1, keepdims=True) + backend.epsilon())\n",
    "        att_weight = backend.expand_dims(att_weight)\n",
    "        return backend.sum(inputs * att_weight, axis=1)\n",
    "\n",
    "class SelfAttention(layers.Layer):\n",
    "    def __init__(self, head_num, head_dim, seed=0, mask_right=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.head_num = head_num\n",
    "        self.head_dim = head_dim\n",
    "        self.output_dim = head_num * head_dim\n",
    "        self.mask_right = mask_right\n",
    "        self.seed = seed\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        glorot = initializers.glorot_uniform(self.seed)\n",
    "        self.WQ = self.add_weight(\"WQ\", (int(input_shape[0][-1]), self.output_dim), initializer=glorot)\n",
    "        self.WK = self.add_weight(\"WK\", (int(input_shape[1][-1]), self.output_dim), initializer=glorot)\n",
    "        self.WV = self.add_weight(\"WV\", (int(input_shape[2][-1]), self.output_dim), initializer=glorot)\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if len(inputs) == 3:\n",
    "            Q_seq, K_seq, V_seq = inputs\n",
    "        else:\n",
    "            Q_seq, K_seq, V_seq= inputs\n",
    "\n",
    "        Q_seq = backend.dot(Q_seq, self.WQ)\n",
    "        Q_seq = backend.reshape(Q_seq, (-1, backend.shape(Q_seq)[1], self.head_num, self.head_dim))\n",
    "        Q_seq = backend.permute_dimensions(Q_seq, (0, 2, 1, 3))\n",
    "\n",
    "        K_seq = backend.dot(K_seq, self.WK)\n",
    "        K_seq = backend.reshape(K_seq, (-1, backend.shape(K_seq)[1], self.head_num, self.head_dim))\n",
    "        K_seq = backend.permute_dimensions(K_seq, (0, 2, 1, 3))\n",
    "\n",
    "        V_seq = backend.dot(V_seq, self.WV)\n",
    "        V_seq = backend.reshape(V_seq, (-1, backend.shape(V_seq)[1], self.head_num, self.head_dim))\n",
    "        V_seq = backend.permute_dimensions(V_seq, (0, 2, 1, 3))\n",
    "\n",
    "        A = tf.matmul(Q_seq, K_seq, adjoint_b=True) / backend.sqrt(backend.cast(self.head_dim, \"float32\"))\n",
    "        A = backend.softmax(A)\n",
    "        O_seq = tf.matmul(A, V_seq, adjoint_a=True)\n",
    "        O_seq = backend.permute_dimensions(O_seq, (0, 2, 1, 3))\n",
    "        O_seq = backend.reshape(O_seq, (-1, backend.shape(O_seq)[1], self.output_dim))\n",
    "        return O_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NRMSModel Class\n",
    "\n",
    "This class builds the NRMS model using the defined layers. It includes:\n",
    "- A news encoder (to encode titles)\n",
    "- A user encoder (to encode user history)\n",
    "- A final model that combines these for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NRMSModel:\n",
    "    def __init__(self, hparams, word2vec_embedding, seed=0):\n",
    "        self.hparams = hparams\n",
    "        self.seed = seed\n",
    "        tf.random.set_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        self.word2vec_embedding = word2vec_embedding\n",
    "        self.model, self.scorer = self._build_graph()\n",
    "        data_loss = \"categorical_crossentropy\" \n",
    "        if self.hparams.loss != \"cross_entropy_loss\": raise ValueError(\"loss not supported\")\n",
    "        opt = tf.keras.optimizers.legacy.Adam(learning_rate=self.hparams.learning_rate)\n",
    "        self.model.compile(loss=data_loss, optimizer=opt)\n",
    "\n",
    "    def _build_userencoder(self, titleencoder):\n",
    "        his_input = tf.keras.Input((self.hparams.history_size, self.hparams.title_size), dtype=\"int32\")\n",
    "        click_presents = tf.keras.layers.TimeDistributed(titleencoder)(his_input)\n",
    "        y = SelfAttention(self.hparams.head_num, self.hparams.head_dim, seed=self.seed)([click_presents]*3)\n",
    "        user_present = AttLayer2(self.hparams.attention_hidden_dim, seed=self.seed)(y)\n",
    "        return tf.keras.Model(his_input, user_present)\n",
    "\n",
    "    def _build_newsencoder(self):\n",
    "        emb = tf.keras.layers.Embedding(self.word2vec_embedding.shape[0], self.word2vec_embedding.shape[1],\n",
    "                                        weights=[self.word2vec_embedding], trainable=True)\n",
    "        inp = tf.keras.Input((self.hparams.title_size,), dtype=\"int32\")\n",
    "        x = emb(inp)\n",
    "        x = tf.keras.layers.Dropout(self.hparams.dropout)(x)\n",
    "        x = SelfAttention(self.hparams.head_num, self.hparams.head_dim, seed=self.seed)([x,x,x])\n",
    "        for u in [400,400,400]:\n",
    "            x = tf.keras.layers.Dense(u, activation=\"relu\")(x)\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "            x = tf.keras.layers.Dropout(self.hparams.dropout)(x)\n",
    "        x = tf.keras.layers.Dropout(self.hparams.dropout)(x)\n",
    "        out = AttLayer2(self.hparams.attention_hidden_dim, seed=self.seed)(x)\n",
    "        return tf.keras.Model(inp, out)\n",
    "\n",
    "    def _build_graph(self):\n",
    "        his_input = tf.keras.Input((self.hparams.history_size, self.hparams.title_size), dtype=\"int32\")\n",
    "        pred_input = tf.keras.Input((None, self.hparams.title_size), dtype=\"int32\")\n",
    "        pred_one = tf.keras.Input((1, self.hparams.title_size), dtype=\"int32\")\n",
    "        pred_one_reshaped = tf.keras.layers.Reshape((self.hparams.title_size,))(pred_one)\n",
    "\n",
    "        titleencoder = self._build_newsencoder()\n",
    "        userencoder = self._build_userencoder(titleencoder)\n",
    "        user_present = userencoder(his_input)\n",
    "        news_present = tf.keras.layers.TimeDistributed(titleencoder)(pred_input)\n",
    "        news_present_one = titleencoder(pred_one_reshaped)\n",
    "\n",
    "        preds = tf.keras.layers.Dot(axes=-1)([news_present, user_present])\n",
    "        preds = tf.keras.layers.Activation(\"softmax\")(preds)\n",
    "\n",
    "        pred_one_out = tf.keras.layers.Dot(axes=-1)([news_present_one, user_present])\n",
    "        pred_one_out = tf.keras.layers.Activation(\"sigmoid\")(pred_one_out)\n",
    "\n",
    "        model = tf.keras.Model([his_input, pred_input], preds)\n",
    "        scorer = tf.keras.Model([his_input, pred_one], pred_one_out)\n",
    "        return model, scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preparation\n",
    "\n",
    "We will now:\n",
    "- Load data using `ebnerd_from_path`.\n",
    "- Apply negative sampling with `sampling_strategy_wu2019`.\n",
    "- Create binary labels.\n",
    "- Convert articles into embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_TITLE_SIZE = 30\n",
    "class hparams_nrms:\n",
    "    # INPUT DIMENTIONS:\n",
    "    title_size: int = DEFAULT_TITLE_SIZE\n",
    "    history_size: int = 20\n",
    "    # MODEL ARCHITECTURE\n",
    "    head_num: int = 20\n",
    "    head_dim: int = 20\n",
    "    attention_hidden_dim: int = 200\n",
    "    # MODEL OPTIMIZER:\n",
    "    optimizer: str = \"adam\"\n",
    "    loss: str = \"cross_entropy_loss\"\n",
    "    dropout: float = 0.2\n",
    "    learning_rate: float = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ebrec.utils._behaviors import ebnerd_from_path, create_binary_labels_column, sampling_strategy_wu2019\n",
    "from ebrec.utils._articles import convert_text2encoding_with_transformers, create_article_id_to_value_mapping\n",
    "from ebrec.utils._nlp import get_transformers_word_embeddings\n",
    "from ebrec.utils._polars import concat_str_columns\n",
    "from ebrec.utils._constants import *\n",
    "\n",
    "PATH = Path(\"~/Git Repositories/ebnerd-benchmark/data\").expanduser()\n",
    "DATASPLIT = \"ebnerd_small\"\n",
    "DUMP_DIR = Path(\"ebnerd_predictions\")\n",
    "DUMP_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "COLUMNS = [\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "    DEFAULT_IMPRESSION_TIMESTAMP_COL,\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "]\n",
    "\n",
    "FRACTION = 0.01\n",
    "df = (\n",
    "    ebnerd_from_path(PATH.joinpath(DATASPLIT, \"train\"), history_size=hparams_nrms.history_size, padding=0)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(sampling_strategy_wu2019, npratio=4, shuffle=True, with_replacement=True, seed=123)\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "\n",
    "dt_split = pl.col(DEFAULT_IMPRESSION_TIMESTAMP_COL).max() - datetime.timedelta(days=1)\n",
    "df_train = df.filter(pl.col(DEFAULT_IMPRESSION_TIMESTAMP_COL) < dt_split)\n",
    "df_validation = df.filter(pl.col(DEFAULT_IMPRESSION_TIMESTAMP_COL) >= dt_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Article Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles = pl.read_parquet(PATH.joinpath(\"articles.parquet\"))\n",
    "TRANSFORMER_MODEL_NAME = \"FacebookAI/xlm-roberta-base\"\n",
    "MAX_TITLE_LENGTH = 30\n",
    "TEXT_COLUMNS_TO_USE = [\"subtitle\", \"title\"]\n",
    "\n",
    "transformer_model = AutoModel.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "transformer_tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "word2vec_embedding = get_transformers_word_embeddings(transformer_model)\n",
    "\n",
    "df_articles, cat_col = concat_str_columns(df_articles, columns=TEXT_COLUMNS_TO_USE)\n",
    "df_articles, token_col_title = convert_text2encoding_with_transformers(df_articles, transformer_tokenizer, cat_col, max_length=MAX_TITLE_LENGTH)\n",
    "article_mapping = create_article_id_to_value_mapping(df_articles, value_col=token_col_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch and shape data with ebrec.models.DataLoaders\n",
    "\n",
    "We use `NRMSDataLoader` from `ebrec.models.newsrec.dataloader` to handle batching and shaping data for the NRMS model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ebrec.models.newsrec.dataloader import NRMSDataLoader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_dataloader = NRMSDataLoader(\n",
    "    behaviors=df_train,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "val_dataloader = NRMSDataLoader(\n",
    "    behaviors=df_validation,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - ETA: 0s - loss: 3.3404 - auc: 0.5124\n",
      "Epoch 1: val_auc improved from -inf to 0.47275, saving model to ebnerd_predictions/weights\n",
      "64/64 [==============================] - 64s 975ms/step - loss: 3.3404 - auc: 0.5124 - val_loss: 2.2068 - val_auc: 0.4727 - lr: 1.0000e-04\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.3352 - auc: 0.6134\n",
      "Epoch 2: val_auc improved from 0.47275 to 0.52803, saving model to ebnerd_predictions/weights\n",
      "64/64 [==============================] - 64s 1000ms/step - loss: 2.3352 - auc: 0.6134 - val_loss: 3.7429 - val_auc: 0.5280 - lr: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x4b9818310>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices()\n",
    "print(\"Devices:\", physical_devices)\n",
    "\n",
    "model = NRMSModel(\n",
    "  hparams_nrms, \n",
    "  word2vec_embedding=word2vec_embedding, \n",
    "  seed=42\n",
    ")\n",
    "model.model.compile(\n",
    "  optimizer=model.model.optimizer, \n",
    "  loss=model.model.loss, \n",
    "  metrics=[\"AUC\"]\n",
    ")\n",
    "\n",
    "callbacks_list = [\n",
    "\t#EarlyStopping\n",
    "\tcallbacks.EarlyStopping(\n",
    "\t\tmonitor=\"val_auc\", \n",
    "\t\tmode=\"max\", \n",
    "\t\tpatience=3, \n",
    "\t\trestore_best_weights=True),\n",
    "\t# ModelCheckpoint\n",
    "\tcallbacks.ModelCheckpoint(\n",
    "    filepath=DUMP_DIR/\"weights\", \n",
    "    monitor=\"val_auc\", \n",
    "    mode=\"max\", \n",
    "    save_best_only=True, \n",
    "    save_weights_only=True,\n",
    "    verbose=1),\n",
    "\t# Learning rate scheduler\n",
    "\tcallbacks.ReduceLROnPlateau(\n",
    "\t\tmonitor=\"val_auc\",\n",
    "\t\tmode=\"max\",\n",
    "\t\tfactor=0.2,\n",
    "\t\tpatience=2,\n",
    "\t\tmin_lr=1e-6)\n",
    "]\n",
    "EPOCHS = 2\n",
    "model.model.fit(train_dataloader, validation_data=val_dataloader, epochs=EPOCHS, callbacks=callbacks_list)\n",
    "model.model.load_weights(DUMP_DIR/\"weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153/153 [==============================] - 126s 821ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AUC:   0%|                                             | 0/2446 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "AUC: 100%|████████████████████████████████| 2446/2446 [00:00<00:00, 3031.35it/s]\n",
      "AUC: 100%|██████████████████████████████| 2446/2446 [00:00<00:00, 116227.30it/s]\n",
      "AUC: 100%|███████████████████████████████| 2446/2446 [00:00<00:00, 49421.06it/s]\n",
      "AUC: 100%|███████████████████████████████| 2446/2446 [00:00<00:00, 47957.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MetricEvaluator class>: \n",
       " {\n",
       "    \"auc\": 0.509017765775553,\n",
       "    \"mrr\": 0.31295053936581163,\n",
       "    \"ndcg@5\": 0.34777084631314387,\n",
       "    \"ndcg@10\": 0.43190050675691727\n",
       "}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ebrec.utils._behaviors import add_prediction_scores\n",
    "from ebrec.evaluation import MetricEvaluator, AucScore, NdcgScore, MrrScore\n",
    "\n",
    "df_test = (\n",
    "    ebnerd_from_path(PATH.joinpath(DATASPLIT, \"validation\"), history_size=hparams_nrms.history_size, padding=0)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "\n",
    "test_dataloader = NRMSDataLoader(\n",
    "    behaviors=df_test,\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    eval_mode=True,\n",
    "    batch_size=16\n",
    ")\n",
    "pred_test = model.scorer.predict(test_dataloader)\n",
    "\n",
    "df_test = add_prediction_scores(df_test, pred_test.tolist())\n",
    "\n",
    "metrics = MetricEvaluator(\n",
    "  df_test[\"labels\"].to_list(), \n",
    "  df_test[\"scores\"].to_list(), \n",
    "  [AucScore(), MrrScore(), NdcgScore(k=5), NdcgScore(k=10)]\n",
    ")\n",
    "metrics.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2446it [00:01, 1559.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipping ebnerd_predictions/predictions.txt to ebnerd_predictions/ebnerd_small_predictions-NRMSModel.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from ebrec.utils._python import write_submission_file, rank_predictions_by_score\n",
    "\n",
    "df_test = df_test.with_columns(\n",
    "    pl.col(\"scores\").map_elements(lambda x: list(rank_predictions_by_score(x))).alias(\"ranked_scores\")\n",
    ")\n",
    "write_submission_file(\n",
    "    impression_ids=df_test[DEFAULT_IMPRESSION_ID_COL],\n",
    "    prediction_scores=df_test[\"ranked_scores\"],\n",
    "    path=DUMP_DIR/\"predictions.txt\",\n",
    "    filename_zip=f\"{DATASPLIT}_predictions-NRMSModel.zip\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
